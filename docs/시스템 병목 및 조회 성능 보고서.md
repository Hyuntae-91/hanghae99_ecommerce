# 시스템 병목 및 조회 성능

## 성능 개선 요약
| 기능                | 인덱스 전    | 인덱스 후 | 비율            | 인덱스                                                                         | 비고                             |
|-------------------|----------|-------|---------------|-----------------------------------------------------------------------------|--------------------------------|
| 상위 인기상품 5개 추출     | 3430 ms  |2333 ms| 32 % 성능 향상    | `order` (state, created_at); `order_item` (order_id, product_id, quantity); |                                |
| 상품 조회(Pagination) | 13950 ms | 15530 ms |               | `product` (state, id); `order` (id);                                        | 오히려 성능 감소! pagination 방식은 O(N) |
| 상품 조회(cursor) |          | 843 ms | 94 %  성능 향상   |                                                                             | 성능 대폭 상향 O(1)                  |
|유저 포인트 히스토리 조회| 207 ms   | 0.105 ms | 99.95 % 성능 향상 | `point_history` (user_id);                                                  ||
|상품 상세 조회| 212 ms   | 0.0976 ms | 99.95 % 성능 향상 | `order_option` (product_id);                                                                            ||
| 쿠폰 조회| 439 ms | 0.063 ms| 99.99 % 성능 향상 | `coupon` (created_at DESC); | |
| 쿠폰 issue 조회|236ms|0.146 ms| 99.94 % 성능 향상 | `coupon_issue` (user_id); | |



## 본 보고서의 목적
이 보고서에서는 이번 프로젝트 시스템에서 발생할 수 있는 서비스 병목 지점을 분석하고 병목이 예상되는 주요 쿼리에 대해 사전 분석 및 테스트를 통해 성능 저하 가능성을 확인하는 것을 목적으로 한다.



## 분석 기준 및 가설 수립

### 분석 기준
트랜잭션이 걸리는 부분이나, 여러 테이블을 조인하는 쿼리 (ex. 베스트 상품 조회) 와 같이 병목이 발생할 만한 지점을 우선적으로 선별하여 분석한다

동시성이 관련된 부분도 병목이 발생할 수 있으므로, 분석 대상에 포함한다.

그 이외에, 조회에서도 index 적용시 어느정도의 성능 항샹이 있는지 확인하고자 한다.


# 눈에띄는 병목이 예상되는 곳
| 항목 | 설명 | 병목 원인                                                                                          | 참고 자료 |
|------|------|------------------------------------------------------------------------------------------------|------------|
| **베스트 상품 조회** | 최근 3일 주문 데이터 기준, 주문 수량 합산 후 TOP 5 | OrderItem과 Order 간 JOIN, 데이터가 1만 건만 넘어도 성능 저하                                                  | [JOIN과 INDEX 관련 문서](https://infoqoch.github.io/db/2023/01/26/db-index-and-join.html) |
| **결제 처리** | PaymentFacade에서 유저 조회 → 주문서 생성 → 가격 계산 → 쿠폰 적용 → 결제 완료까지 전 과정에 트랜잭션 적용 | 트랜잭션 내에서 빈번한 DB 통신 → 네트워크 비용 증가 및 동시성 병목 가능성                                                   | 없음 |
| **선착순 쿠폰 발급 처리** | 쿠폰 수량 한정 시 동시성 제어 필요 | 공유 자원(Coupon.issued)에 대한 동시 접근 → Row Lock/Table Lock 자주 발생                                     | [동시성 처리 개념](https://velog.io/@sonny__/%EB%8F%99%EC%8B%9C%EC%84%B1-%EC%9D%B4%EC%8A%88%EB%8A%94-%EC%96%B4%EB%96%BB%EA%B2%8C-%ED%95%B4%EA%B2%B0%ED%95%B4%EC%95%BC-%ED%95%A0%EA%B9%8C), [Lock 종류](https://galid1.tistory.com/804) |
| **상품 리스트 조회** | 대량 데이터 조회 시 pagination 적용 | OFFSET 기반 페이지네이션은 데이터 양 증가 시 성능 저하. 대신 lastId 를 기반으로 order by 한 id 이전, 이후 데이터를 불러 오는 방식이 더 효율적 | [pagination 단점과 해법](https://binux.tistory.com/148) |

## 상위 상품 5개 조회 테스트 및 결과
### 조회 쿼리
```sql
SELECT p.*
FROM product p
JOIN (
  SELECT oi.product_id
  FROM order_item oi
  WHERE oi.order_id IN (
      SELECT o.id
      FROM `order` o
      WHERE o.state = 1
        AND o.created_at >= DATE_SUB(NOW(), INTERVAL 3 DAY)
  )
  GROUP BY oi.product_id
  ORDER BY SUM(oi.quantity) DESC
  LIMIT 5
) best ON p.id = best.product_id;
```

### 인덱스 없이 조회
```text
-> Nested loop inner join  (cost=3.9 rows=0) (actual time=3428..3430 rows=5 loops=1)
    -> Table scan on best  (cost=2.5..2.5 rows=0) (actual time=3427..3427 rows=5 loops=1)
        -> Materialize  (cost=0..0 rows=0) (actual time=3427..3427 rows=5 loops=1)
            -> Limit: 5 row(s)  (actual time=3427..3427 rows=5 loops=1)
                -> Sort: `sum(oi.quantity)` DESC, limit input to 5 row(s) per chunk  (actual time=3427..3427 rows=5 loops=1)
                    -> Table scan on <temporary>  (actual time=3409..3416 rows=99992 loops=1)
                        -> Aggregate using temporary table  (actual time=3409..3409 rows=99992 loops=1)
                            -> Nested loop inner join  (cost=982206 rows=49822) (actual time=151..2867 rows=899999 loops=1)
                                -> Filter: (oi.order_id is not null)  (cost=103252 rows=996442) (actual time=0.752..685 rows=999999 loops=1)
                                    -> Table scan on oi  (cost=103252 rows=996442) (actual time=0.751..636 rows=999999 loops=1)
                                -> Filter: ((o.state = 1) and (o.created_at >= <cache>((now() - interval 3 day))))  (cost=0.782 rows=0.05) (actual time=0.00202..0.00208 rows=0.9 loops=999999)
                                    -> Single-row index lookup on o using PRIMARY (id=oi.order_id)  (cost=0.782 rows=1) (actual time=0.00184..0.00186 rows=0.9 loops=999999)
    -> Single-row index lookup on p using PRIMARY (id=best.product_id)  (cost=0.299 rows=1) (actual time=0.618..0.618 rows=1 loops=5)
```
- 999,999 개의 데이터를 full scan 을 하게 되므로 굉장히 느리고, 시간이 오래걸리게 된다.
- 소요시간은 약 3430 ms

### 인덱스 적용후 데이터 속도 측정

```text
-> Nested loop inner join  (cost=7.5 rows=0) (actual time=2335..2336 rows=5 loops=1)
    -> Table scan on best  (cost=2.5..2.5 rows=0) (actual time=2333..2333 rows=5 loops=1)
        -> Materialize  (cost=0..0 rows=0) (actual time=2333..2333 rows=5 loops=1)
            -> Limit: 5 row(s)  (actual time=2333..2333 rows=5 loops=1)
                -> Sort: `sum(oi.quantity)` DESC, limit input to 5 row(s) per chunk  (actual time=2333..2333 rows=5 loops=1)
                    -> Table scan on <temporary>  (actual time=2316..2323 rows=99992 loops=1)
                        -> Aggregate using temporary table  (actual time=2316..2316 rows=99992 loops=1)
                            -> Nested loop inner join  (cost=584098 rows=448926) (actual time=0.546..1897 rows=899999 loops=1)
                                -> Filter: ((o.state = 1) and (o.created_at >= <cache>((now() - interval 3 day))))  (cost=90279 rows=448926) (actual time=0.52..296 rows=899999 loops=1)
                                    -> Covering index range scan on o using idx_order_state_created_at over (state = 1 AND '2025-04-15 08:31:48' <= created_at)  (cost=90279 rows=448926) (actual time=0.517..167 rows=899999 loops=1)
                                -> Covering index lookup on oi using idx_order_item_order_id_product_id_quantity (order_id=o.id)  (cost=1 rows=1) (actual time=0.00139..0.00164 rows=1 loops=899999)
    -> Single-row index lookup on p using PRIMARY (id=best.product_id)  (cost=1.02 rows=1) (actual time=0.605..0.605 rows=1 loops=5)
```

#### 인덱스 조건
```sql
CREATE INDEX idx_order_state_created_at ON `order` (state, created_at);
CREATE INDEX idx_order_item_order_id_product_id_quantity ON order_item (order_id, product_id, quantity);
```

- 조회 조건에서 order 에 state 와 created_at 을 조건을 걸고 있으므로, 관련하여 복합 인덱스 추가
- [created_at 인덱스 조건 장단점](https://www.inflearn.com/community/questions/1344742/created-at-%EC%97%90-index-%EA%B1%B0%EB%8A%94%EA%B2%83%EA%B3%BC-%EC%A7%80%EC%86%8D%EC%A0%81%EC%9D%B8-%EB%8D%B0%EC%9D%B4%ED%84%B0-%EC%A6%9D%EA%B0%80?srsltid=AfmBOoo9rpXXB0b6ynfOLKUN87x9ZprF6A5wpCLWUPA-qsmPgegJVFFe)
- 조회성능은 향상되지만, 쓰기 속도가 느려진다.
- order item 에서도 조건에 사용하는 컬럼들을 index 로 추가

#### 성능 분석
- 인덱스 적용 후 2333 ms 로 성능이 약 1000 ms 가량 빨라졌다.
- **GROUP BY + ORDER BY SUM(quantity) DESC LIMIT 5** 이 구간이 가장 큰 병목
  - 2316 ms 로 대부분의 시간을 잡아먹고 있음
- 성능은 상당히 개선되었지만, 여전히 집계하는데에는 시간이 상당히 걸림
- index 만으로는 한계가 있음. 결국 **집계** 를 담당해야 하기에, 통계 테이블을 따로 두는게 가장 좋은 해법이다.
- 개선안1 : 별도 통계 테이블 설계 및 일정 간격 배치 처리
- 개선안2 : redis 와 같은 캐시 저장소를 도입하고 일정 간격 배치 처리


## 상품 리스트 검색
### 발생할 수 있는 쿼리
```sql
SELECT
    p.id AS product_id,
    p.name,
    p.price,
    p.state,
    p.created_at,
    o.id AS option_id,
    o.size,
    o.stock_quantity
FROM
    product p
LEFT JOIN
    order_option o ON p.id = o.product_id
WHERE
    p.state = 1
LIMIT 10 OFFSET 0;
```

### 인덱스 없이 조회
```text
-> -> Limit: 10 row(s)  (cost=9.83e+9 rows=10) (actual time=11.8..11.8 rows=10 loops=1)
    -> Left hash join (o.product_id = p.id)  (cost=9.83e+9 rows=98.3e+9) (actual time=11.8..11.8 rows=10 loops=1)
        -> Filter: (p.state = 1)  (cost=101827 rows=98594) (actual time=0.847..0.874 rows=218 loops=1)
            -> Table scan on p  (cost=101827 rows=985937) (actual time=0.845..0.861 rows=218 loops=1)
        -> Hash
            -> Table scan on o  (cost=2.11 rows=997458) (actual time=10..10.3 rows=4956 loops=1)
            
-> Limit/Offset: 10/500000 row(s)  (cost=9.83e+9 rows=10) (actual time=13950..13950 rows=10 loops=1)
    -> Left hash join (o.product_id = p.id)  (cost=9.83e+9 rows=98.3e+9) (actual time=1.79..13939 rows=500010 loops=1)
        -> Filter: (p.state = 1)  (cost=100902 rows=98594) (actual time=0.164..410 rows=1e+6 loops=1)
            -> Table scan on p  (cost=100902 rows=985937) (actual time=0.163..364 rows=1e+6 loops=1)
        -> Hash
            -> Table scan on o  (cost=1.69 rows=997458) (actual time=0.873..166 rows=500836 loops=1)
```
- 인덱스가 없어서 전체 테이블 스캔 발생
- 11.8 ms 로 상당히 빠른 모습
- **중요!!** 테이블의 중간지점인 500,000 을 OFFSET 으로 주면, 조회시간 급격히 감소 
  - 13950 ms 로 매우매우 느려짐
  - pagination -> 성능에 아주 좋지 않은 쿼리임 (OFFSET 으로 주어진 50만건의 row 를 모두 읽음)

### 인덱스 적용후 데이터 속도 측정
```test
-> Limit: 10 row(s)  (cost=49.2e+9 rows=10) (actual time=2.28..2.32 rows=10 loops=1)
    -> Left hash join (o.product_id = p.id)  (cost=49.2e+9 rows=492e+9) (actual time=2.28..2.32 rows=10 loops=1)
        -> Index lookup on p using idx_product_state_id (state=1)  (cost=55048 rows=492968) (actual time=0.663..0.68 rows=218 loops=1)
        -> Hash
            -> Table scan on o  (cost=0.86 rows=997458) (actual time=0.826..1.1 rows=4956 loops=1)
            
-> Limit/Offset: 10/500000 row(s)  (cost=49.2e+9 rows=10) (actual time=15530..15531 rows=10 loops=1)
    -> Left hash join (o.product_id = p.id)  (cost=49.2e+9 rows=492e+9) (actual time=2.47..15519 rows=500010 loops=1)
        -> Index lookup on p using idx_product_state_id (state=1)  (cost=55580 rows=492968) (actual time=0.694..1771 rows=1e+6 loops=1)
        -> Hash
            -> Table scan on o  (cost=0.86 rows=997458) (actual time=0.892..364 rows=500836 loops=1)
```

#### 인덱스 조건
```sql
CREATE INDEX idx_product_state_id ON product (state, id);
CREATE INDEX idx_order_product_id ON `order` (id);
```
- p.state = 1 조건과, p.id ORDER BY 등에 쓰기 위한 인덱스
- ```JOIN``` 시 사용되는 ```product_id``` 에 대한 인덱스

#### 성능 분석
- 2.28 ms 로 성능 향상 (단, Offset 이 낮은 경우에만)
- 50만을 offset 으로 준 결과, 15530 ms 로 인덱스를 적용하기 전보다 오히려 더 느려짐.

### Seek 방식으로 전환
```sql
EXPLAIN ANALYZE
SELECT
   p.id AS product_id,
   p.name,
   p.price,
   p.state,
   p.created_at,
   o.id AS option_id,
   o.size,
   o.stock_quantity
FROM
   product p
      LEFT JOIN
   order_option o ON p.id = o.product_id
WHERE
   p.state = 1
  AND p.id > 500000
ORDER BY p.id
   LIMIT 10;
```

#### seek 방식 전환 후 결과 및 분석
```text
-> Limit: 10 row(s)  (actual time=843..843 rows=10 loops=1)
    -> Sort: p.id, limit input to 10 row(s) per chunk  (actual time=843..843 rows=10 loops=1)
        -> Stream results  (cost=49.2e+9 rows=492e+9) (actual time=509..806 rows=500000 loops=1)
            -> Left hash join (o.product_id = p.id)  (cost=49.2e+9 rows=492e+9) (actual time=509..654 rows=500000 loops=1)
                -> Filter: ((p.state = 1) and (p.id > 500000))  (cost=98847 rows=492968) (actual time=0.25..148 rows=500000 loops=1)
                    -> Index range scan on p using PRIMARY over (500000 < id)  (cost=98847 rows=492968) (actual time=0.246..115 rows=500000 loops=1)
                -> Hash
                    -> Table scan on o  (cost=0.47 rows=997458) (actual time=0.807..172 rows=999999 loops=1)
```
- 성능이 843 ms 로 어마어마하게 향상됨
- pagination 방식을 지양하고, cursor 방식으로 전환하는걸 추천
- pagination O(N) / cursor O(1) -> 차이 극명함


## 유저 포인트 히스토리 조회
### 발생할 수 있는 쿼리
```sql
SELECT *
FROM point_history
WHERE user_id = 7297
ORDER BY created_at DESC
LIMIT 100 OFFSET 0;
```

### 인덱스 없이 조회
```text
-> Limit: 100 row(s)  (cost=100473 rows=100) (actual time=207..207 rows=25 loops=1)
    -> Sort: point_history.created_at DESC, limit input to 100 row(s) per chunk  (cost=100473 rows=997442) (actual time=207..207 rows=25 loops=1)
        -> Filter: (point_history.user_id = 7297)  (cost=100473 rows=997442) (actual time=9.31..207 rows=25 loops=1)
            -> Table scan on point_history  (cost=100473 rows=997442) (actual time=0.642..178 rows=999999 loops=1)
```
- 전체 테이블 스캔 발생
- 207 ms 소요시간

### 인덱스 적용 후 속도 측정
```text
-> Limit: 100 row(s)  (cost=8.75 rows=25) (actual time=0.105..0.107 rows=25 loops=1)
    -> Sort: point_history.created_at DESC, limit input to 100 row(s) per chunk  (cost=8.75 rows=25) (actual time=0.104..0.106 rows=25 loops=1)
        -> Index lookup on point_history using idx_point_history_user (user_id=7297)  (cost=8.75 rows=25) (actual time=0.0887..0.0915 rows=25 loops=1)
```

### 인덱스 조건
```sql
CREATE INDEX idx_point_history_user ON point_history (user_id);
```
- 포인트 사용 내역은 주로 user_id 별로 조회를 하게 되므로, user_id 에 조건 추가
- 0.105 ms 로 성능의 엄청난 향상
- 조회 row 수도 user_id 의 history 만큼만 조회하므로 속도 빠름

## 상품 상세 조회
### 발생할 수 있는 쿼리
```sql
SELECT *
FROM order_option
WHERE product_id = 24055;
```

### 인덱스 없이 조회
```text
-> Filter: (order_option.product_id = 24055)  (cost=100459 rows=99746) (actual time=5.67..212 rows=26 loops=1)
    -> Table scan on order_option  (cost=100459 rows=997458) (actual time=0.915..182 rows=999999 loops=1)
```
- 전체 테이블 스캔 발생
- 212 ms 소요시간

### 인덱스 적용 후 속도 측정
```text
-> Index lookup on order_option using idx_order_option_product_id (product_id=24055)  (cost=9.1 rows=26) (actual time=0.0929..0.0976 rows=26 loops=1)
```

### 인덱스 조건
```sql
CREATE INDEX idx_order_option_product_id ON order_option (product_id);
```
- 상품 조회시, product_id 를 참고삼아 조회하므로 product_id 에 인덱스 추가
- 0.0929 ms 로 성능 향상

## 쿠폰 조회
### 발생할 수 있는 쿼리
```sql
SELECT *
FROM coupon
ORDER BY created_at DESC
LIMIT 20 OFFSET 0;
```

### 인덱스 없이 조회
```text
-> Limit: 20 row(s)  (cost=100783 rows=20) (actual time=439..439 rows=20 loops=1)
    -> Sort: coupon.created_at DESC, limit input to 20 row(s) per chunk  (cost=100783 rows=995948) (actual time=439..439 rows=20 loops=1)
        -> Table scan on coupon  (cost=100783 rows=995948) (actual time=0.123..330 rows=999999 loops=1)
```
- 전체 테이블 스캔 발생
- 439 ms 소요시간

### 인덱스 적용 후 속도 측정
```text
-> Limit: 20 row(s)  (cost=0.0522 rows=20) (actual time=0.0487..0.063 rows=20 loops=1)
    -> Index scan on coupon using idx_coupon_created_at  (cost=0.0522 rows=20) (actual time=0.0479..0.0614 rows=20 loops=1)
```

### 인덱스 조건
```sql
CREATE INDEX idx_coupon_created_at ON coupon (created_at DESC);
```
- 관리자가 쿠폰 조회할때, created_at 으로 정렬하여 보므로, created_at 에 index
- 0.063 ms 소요시간



## 사용자 쿠폰 조회
### 발생할 수 있는 쿼리
```sql
SELECT *
FROM coupon_issue
WHERE user_id = ?
ORDER BY created_at DESC
LIMIT 10 OFFSET 0;
```

### 인덱스 없이 조회
```text
-> Limit: 10 row(s)  (cost=100524 rows=10) (actual time=236..236 rows=10 loops=1)
    -> Sort: coupon_issue.created_at DESC, limit input to 10 row(s) per chunk  (cost=100524 rows=997152) (actual time=236..236 rows=10 loops=1)
        -> Filter: (coupon_issue.user_id = 25085)  (cost=100524 rows=997152) (actual time=2.05..236 rows=27 loops=1)
            -> Table scan on coupon_issue  (cost=100524 rows=997152) (actual time=0.712..206 rows=999999 loops=1)
```
- 전체 테이블 스캔 발생
- 236 ms 소요시간

### 인덱스 적용 후 속도 측정
```text
-> Limit: 10 row(s)  (cost=9.45 rows=10) (actual time=0.145..0.146 rows=10 loops=1)
    -> Sort: coupon_issue.created_at DESC, limit input to 10 row(s) per chunk  (cost=9.45 rows=27) (actual time=0.144..0.145 rows=10 loops=1)
        -> Index lookup on coupon_issue using idx_coupon_issue_user (user_id=25085)  (cost=9.45 rows=27) (actual time=0.127..0.131 rows=27 loops=1)
```

### 인덱스 조건
```sql
CREATE INDEX idx_coupon_issue_user ON coupon_issue (user_id);
```
- 유저가 본인의 쿠폰만 조회할 것이므로, user_id 로 인덱싱
- 0.146 ms 소요시간


# 최적화 결론
## Pagination 사용 자제
- Pagination 방식은 생각 이상으로 성능 저하를 부른다. O(N) 시간 복잡도를 가짐
- Cursor 방식으로 조회를 하게 되면 O(1) 시간 복잡도를 가지며, 성능에 어마어마한 향상을 가져온다.

## index 조건과 복합 index 조건은 조회 성능을 향상 시킨다
- [인덱스의 구조](https://jeong-pro.tistory.com/242)
- 인덱싱을 하므로써, 조회하는 row 의 수를 줄이고, 조회하는 성능을 극대화 할 수 있다.
- 하지만, indexing 이 만능은 아니다 -> 과도한 indexing 추가는, 오히려 성능을 하락시킬 수 있다.
- 집계를 하는 경우에는 index 에 의존하지말고, 통계 테이블이나 캐싱 기술을 활용하는게 더 좋다.